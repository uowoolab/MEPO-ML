from datetime import date
from pathlib import Path


def write_to_cif(cif_name, lattice, symbols, labels, frac_xyz, charges, dst_path):
    # Create preambles for the new CIF file
    new_cif = "# Charges generated by MEPO-ML\n"
    new_cif += f"data_{cif_name}\n"
    new_cif += "_audit_creation_date              "
    new_cif += date.today().strftime("%Y-%m-%d") + "\n"
    new_cif += "_audit_creation_method            MEPO-ML\n"

    # Create cell info for the new CIF file
    new_cif += f"_cell_length_a                    {lattice.a:.6f}\n"
    new_cif += f"_cell_length_b                    {lattice.b:.6f}\n"
    new_cif += f"_cell_length_c                    {lattice.c:.6f}\n"
    new_cif += f"_cell_angle_alpha                 {lattice.alpha:.6f}\n"
    new_cif += f"_cell_angle_beta                  {lattice.beta:.6f}\n"
    new_cif += f"_cell_angle_gamma                 {lattice.gamma:.6f}\n"
    new_cif += f"_cell_volume                      {lattice.volume:.6f}\n"

    # [ASSUMED P1] Create symmetry info for the new CIF file
    new_cif += "_symmetry_space_group_name_H-M    P1\n"
    new_cif += "_symmetry_Int_Tables_number       1\n"
    new_cif += "loop_\n"
    new_cif += "    _symmetry_equiv_pos_site_id\n"
    new_cif += "    _symmetry_equiv_pos_as_xyz\n"
    new_cif += "    1  x,y,z\n"

    # Create atom info for the new CIF file
    new_cif += "loop_\n"
    new_cif += "    _atom_site_type_symbol\n"
    new_cif += "    _atom_site_label\n"
    new_cif += "    _atom_site_fract_x\n"
    new_cif += "    _atom_site_fract_y\n"
    new_cif += "    _atom_site_fract_z\n"
    new_cif += "    _atom_type_partial_charge\n"

    # Adjust widths for the symbols and labels column
    symbol_width = len(max(symbols, key=len))
    label_width = len(max(labels, key=len))

    # Loop over all atoms and create info line for each of them
    for symbol, label, frac, charge in zip(symbols, labels, frac_xyz, charges):
        new_cif += f"    {symbol:{symbol_width}}  {label:{label_width}}  "
        new_cif += "{:.6f}  {:.6f}  {:.6f}  ".format(*frac) + f"{charge:.6f}\n"

    dst_path.joinpath(cif_name + "_mepoml.cif").write_text(new_cif)


def process_cif(cif_path):
    import warnings

    import numpy as np
    from pymatgen.analysis.local_env import IsayevNN
    from pymatgen.io.cif import CifParser

    from descriptors import get_dist_features, get_shell_features
    from elements import atomic_properties

    bond_table_func = IsayevNN(tol=0.5, allow_pathological=True).get_bonded_structure
    scaler_npz = np.load("feature_scaler.npz")

    # TMP solution for messed up of using the scaler and the mean
    scaler_u = scaler_npz["scale"]
    scaler_s = scaler_npz["mean"]

    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        cif_struct = CifParser(cif_path).get_structures(primitive=False).pop()

    n_atoms = len(cif_struct)
    # atomic_numbers = np.array([atom.specie.number for atom in cif_struct])
    atom_symbols = [atom.specie.symbol for atom in cif_struct]
    atom_labels = []
    label_counter = {element: 0 for element in set(atom_symbols)}
    for symbol in atom_symbols:
        label_counter[symbol] += 1
        atom_labels.append(f"{symbol}{label_counter[symbol]}")

    cif_bond_info = bond_table_func(cif_struct).as_dict()["graphs"]["adjacency"]
    bonds_ij = np.array(
        [
            (i, bond["id"], *bond["to_jimage"])
            for i, bonds in enumerate(cif_bond_info)
            for bond in bonds
        ]
    )
    bonds_ji = np.hstack([bonds_ij[:, [1, 0]], -bonds_ij[:, 2:]])
    bonds_full = np.vstack([bonds_ij, bonds_ji])

    f_atom = np.array([atomic_properties[symbol] for symbol in atom_symbols])
    f_dist = get_dist_features(cif_struct, atom_symbols, n_atoms)
    f_shell = get_shell_features(bonds_full, f_atom, n_atoms)

    node_features = (np.hstack([f_atom, f_dist, f_shell]) - scaler_u) / scaler_s
    edges = bonds_full[:, [0, 1]].T

    return {
        "cif_name": cif_path.name.removesuffix(".cif").removesuffix("_repeat"),
        "lattice": cif_struct.lattice,
        "symbols": atom_symbols,
        "labels": atom_labels,
        "frac_xyz": cif_struct.frac_coords,
        "descriptors": node_features,
        "bonds": edges,
    }


def main_single(cif_str, cif_dst=None):
    cif_path = Path(cif_str)
    assert cif_path.exists(), f"{cif_str} DOES NOT EXIST."

    if cif_dst is None:
        dst_path = cif_path.parent
    else:
        dst_path = Path(cif_dst)
        if not dst_path.is_dir():
            dst_path.mkdir()

    import torch
    from torch_geometric.data import Data

    from model import MEPOML_GAT

    device = torch.device("cuda")
    model_path = Path("gat.pt")

    data_dict = process_cif(cif_path)

    x_np = data_dict.pop("descriptors")
    edge_np = data_dict.pop("bonds")
    graph_data = Data(
        x=torch.tensor(x_np, dtype=torch.float).contiguous(),
        edge_index=torch.tensor(edge_np, dtype=torch.long).contiguous(),
    )

    model = MEPOML_GAT()
    model.load_state_dict(torch.load(model_path))
    model = model.to(device)
    model.eval()
    with torch.inference_mode():
        model_y = model_y = model(graph_data.to(device))
        charges = model_y.cpu().flatten().numpy()

    data_dict["charges"] = charges
    data_dict["dst_path"] = dst_path
    write_to_cif(**data_dict)


def main_batch(cif_src, cif_dst):
    src_path = Path(cif_src)
    assert src_path.is_dir(), f"{cif_src} IS NOT A DIRECTORY."
    src_glob = list(src_path.glob("*.cif"))

    dst_path = Path(cif_dst)
    if not dst_path.is_dir():
        dst_path.mkdir()

    import torch

    n_jobs = 20
    torch.set_num_threads(4)
    torch.set_num_interop_threads(4)
    device = torch.device("cuda")
    model_path = Path("gat.pt")

    # model = MEPOML_GAT()
    # model.load_state_dict(torch.load(model_path))
    # model = model.to(device)
    # model.eval()

    import multiprocessing as mp

    from tqdm import tqdm

    with (
        mp.Pool(processes=n_jobs) as pool,
        tqdm(total=len(src_glob), ncols=0, ascii=True) as progress,
        # torch.inference_mode(),
    ):
        for data_dict in pool.imap_unordered(process_cif, src_glob):
            x_np = data_dict.pop("descriptors")
            edge_np = data_dict.pop("bonds")
            # graph_data = Data(
            #     x=torch.tensor(x_np, dtype=torch.float).contiguous(),
            #     edge_index=torch.tensor(edge_np, dtype=torch.long).contiguous(),
            # )
            # model_y = model(graph_data.to(device))
            # charges = model_y.cpu().flatten().numpy()
            # data_dict["charges"] = charges
            # data_dict["dst_path"] = dst_path
            # write_to_cif(**data_dict)
            progress.update()


if __name__ == "__main__":
    from argparse import ArgumentParser

    ap = ArgumentParser(
        description="Predict REPEAT charges and output to a new CIF file."
    )
    ap.add_argument(
        "--cif", type=str, metavar="CIF", help="path to the CIF of interest"
    )
    ap.add_argument(
        "--src",
        type=str,
        metavar="SRC_DIR",
        help="Source directory for batch predictions",
    )
    ap.add_argument(
        "--dst",
        type=str,
        metavar="DST_DIR",
        help="Destination directory for the output CIF file",
    )
    args = ap.parse_args()
    if all([args.cif, not args.src, not args.dst]):
        main_single(args.cif)
    elif all([args.cif, not args.src, args.dst]):
        main_single(args.cif, args.dst)
    elif all([not args.cif, args.src, args.dst]):
        main_batch(args.src, args.dst)
    else:
        print("Invalid arguments, please only use the following combination:")
        print("\t1. only --cif")
        print("\t2. --cif and --dst")
        print("\t3. --src and --dst")
